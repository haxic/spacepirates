
3D model
	Episode 2
	Vertex Array Object (VAO)
		An object in which data about a 3d model is stored. It's essentially a list of attribute lists that contains some type of data, for example:
		0 vertex positions
		1 vertex colors
		2 mormal vectors
		3 texture coordinates
		4 etc
		...
		where each data set e.g. vertex positions, is stored as an VBO. Each VAO has an unique ID, which is used to access it.
	
	Episode 2
	Vertex Buffer Object (VBO)
		A VBO is essentially just an array of numbers.
	
	Episode 3
	Optimization
		Use index buffer for representing polygons instead of coordinates. The indexes points at the coordinates.
		Basically, polygons may share the same coordinate (x,y,z) through a index (i), rather than having one duplicate each of the (x,y,z) coordinate.
		This reduces the amount of data required to represent the 3d model. 

Episode 4-5
Uniform Variables
	Whereas model data comes directly from models, uniform variables can be input directly through java.
	Uniform variables are typically used to create lighting, fog, sunlight etc.	

Episode 4-5
OpenGL Shader Language (GLSL)
	Used for programming Shaders.
	
	Vertex Shader
		Executes one time for each vertex in the object that is being rendered.
		Model data (BAOs from VAOs attribute list) and uniform variables are passed to the vertex shader.
		The vertex shader may manipulate the inputed data.
		Outputs data to the Fragment Shader.
	Fragment Shader
		Executes one time for each pixel that the object covers on the screen.
		It takes the output from the fragment shader as input, and interpolates the data to calculate a pixel.
		It outputs the color of the pixel.


Episode 7
Rendering multiple objects with the same model
	Instead of loading the same model e.g. a 100 times to represent 100 different objects,
	we simply use one model that we render 100 times. To do this, we use transformation matrixes.
	The transformation matrix is calculated by the CPU and is used to determine an entity's position, orientation and scale in the 3d world.
	This matrix is passed into the vertex shader, which multiplies it with each vertex position.
	All you need to do, is pass a new transformation matrix for every entity that is going to get rendered, using
	the entity's position, orientation and scale.
Episode 7+8
Model Matrix
	Translate (move position)
	Rotate
	Scale
		 __
	->	|__|

Episode 8 (REMEMBER 12:00-isch!!!)
Projection Matrix
	While the transformation matrix manipulates an entity's position, orientation and scale in the 3d world,
	the projection matrix works like the eye from which we view the 3d world from.
	The position and orientation of the eye can be moved around, but many other attributes can be used as well.
	For example, we are using a 3d perspective projection matrix, which causes objects to look smaller at a longer distance.
	It can also decide how close or far away objects can be to get rendered etc.
	
	
		  /|
		 / |
	->	|  |
		 \ |
		  \|

Episode 8
View Matrix

Episode 11
Lighting
	Normal Vector
		Vector that a vertex is facing.
	Per-Pixel Lighting
		Requires light position and color, and entity normal vectors.
		Use dot product of normal vector and to-light vector to determine how much a light source light up a vertex.
		The closer the normal and to-light vectors are, the more brightness.
	Episode 12
	Specular Lighting
		shineDamper and reflectivity
	
	Episode 13
	Ambient lighting
		Simply add a minimum variable larger then 0 when calculating brightness.
		This could e.g. be value set directly in the shader or passed through a uniform variable.

Episode 13
More optimization - for rendering multiple entities using the same model
	Instead of loading and unbinding the same model, including shaders and uniform variables, for every model using the same model,
	load and unbind everything once and render all entities using the model in one go.
	
	The way this is done, is that we process each entity we want to render before we start rendering.
	We store each entity in a batch based on which model it uses.
	When rendering, it takes a batch of entities, load the model, renders all entities, then unbinds the model again.
	This is done for each batch of entities.
	This method improves performance of the GPU a lot, when there are multiple entities using the same models.
	
	Further improvement is to maintain the hashmap that keeps track of all the batches of entities,
	rather than clearing it and process all entities that should be rendered each frame.
	This method improves performance of the CPU a bit, when there are many entities.
	
SKIPPED:
	Episode 14
	Simple terrain

Episode 15
Simple transparency and lighting on back-faces
	This works for two-sided faces only. To get this to work, back-culling needs to be disabled.
	Simply discard updating a pixel if the current fragment's texture color is transparent.
	
	To fix lighting when looking at the back-side of a face, invert the normal in the fragment shader,
	if the normal is facing away from the camera. This is calculated using the dot product between the to-camera vector
	and the normal vector.

SKIPPED:
	Episode 16
	Fog
		Math for distance in GLSL: length(vec3 position1, vec3 position2)

SKIPPED:
Episode 17
	Multitexturing
		Blend map for mixing textures.
		Possibly useful for:
			terrain texturing
			phasing from undamaged to damaged/destroyed textures
			reflection or similar attributes on specific places on models, e.g. reflection image.
		Use multitexturing by activating and binding textures;
			GL13.glActivateTexture(GL13.GL_TEXTURE<X>) and GL11.glBindTexture(GL11.GL_TEXTURE_2D, texture.getID())
			and use uniform sampler2D variables to access them in the shader.

Episode 18
Player movement and Time-step

Skipped, BUT:
Episode 19
3rd person camera
	Instead of implementing third person camera, I implemented a flying FPS camera that can roll, pitch, yaw and move in all directions etc.

Episode 20
Mipmapping
	A technique to optimize the rendering of textures. Built in function in OpenGL.
	It automatically lowers resolution on textures that are far away.
	
Skipped:
	Episode 21
	Terrain Height Maps
		Could essentially be a grey scale image where white is the lowest height and black is the highest height.
		Possibly useful for:
			for procedural generation of worlds
	Episode 22
	Terrain Collision Detection

Episode 23
Texture Atlases
	Having entities with the same type of model using different textures.
	This allows a model to contain multiple texture sets, or atlases, which it could use.

Skipped:
	Episode 24
	 Rendering GUIs
	 	Just a new render system for 2d.
	 	Transparency for 2d can be done by (remember that it needs to be disabled after being used),
	 	also, depth test for transparency must be turned off if they should be able to stack on top of each other
	 	(which probably is why this is not used in 3d!):
	 	GL11.glEnable(GL11.GL_BLEND)
	 	GL11.glBlendFunc(GL11.GL_SRC_ALPHA, GL11.GL_ONE_MINUS_SRC_ALPHA)
	 	GL11.glDisable(GL11.GL_BLEND)

Episode 25
Multiple Lights
	Nothing new really. Instead of passing one light source, we pass an array of light sources. What's important here,
	is that there is a set (not variable) number of max lights that must be sent passed to the shaders.
	However, I modified it by adding an extra uniform numberOfLights that decides how many lights the shaders can loop through,
	which is the lights.size() up to MAX_LIGHTS in java code.
	
Episode 26
Point Lights
	Basically, add a distance base factor that reduces light.

Episode 27
Skybox - Cube Map Textures
	Some information on Texture-parameters etc: https://open.gl/textures
	The vertex shader for the cube map will use a 3d vector instead of 2d vector,
	since the cube map is sampled using a direction vector, not a 2d texture coordinate.
	The fragment shader uses a cube sampler, not a 2d sampler.
	When loading the view matrix to the shader, set matrix positions 3,0 3,1 and 3,2 to 0 to not do translation (change position) 
	
Skipped:
	Episode 28
		Day/Night skybox - with fog matching terrain
			Rotating skybox.
			Blending between two skyboxes.
			Terrain stuff. Maybe useful for planets.
			mix(color1, color2, factor) in fragment shader, useful for making things fade.
	Episode 29
		Mouse Picking
			Sends a ray outwards from the mouse position on the screen.
			This is an alternative from using the cameras direction.
			Can be used to click objects etc.
	<Water tutorial>
		Learn about FBOs here.
		Normal map - Episode 7
	Episode 30
		Cel Shading
			Probably not useful for my project at all.
		
Episode 31
Normal mapping
	Take a look at this again. Maybe improve?
		
Episode 32
Font Rendering
	Take a look at this again if you need text.
	
Episode 33
Distance Field Text Rendering
	Used for making smooth edged for text. Can also add shadow and border effects.

Episode 34
Patricle Effects
	The particles should have a position in 3d space, but should always face the screen directly,
	but may be rotated around the exis pointing towards the screen.
	
	We need to: view matrix * model matrix = modelview matrix, where the modelview matrix contains no rotation,
	except for rotating around the axes pointing towards the screen.
	
Episode 35
Animating Particle Textures
	By having all the frames of a particle in one texture, we can use a texture atlas to pick which frame in the texture,
	that a particle should use. To make the transition look nice, we mix the current and the next texture frames,
	depending on how far a particle has progressed its life.

Episode 36
Instanced Rendering
	The idea is to render multiple objects in one go rather than one by one, as it can be done much faster.
	Currently, all non-vertex data, or instance data, is passed as uniform variables to the shaders.
	Instead of doing that, we upload instance data as VBOs to the VAO instead (in addition to vertex data).
	With all model data and all instances data uploaded in one go, opengl can proceed to render all of them in one go.
	This means of course that all instance data (VBOs) in the VAO needs to be updated.
	Another thing that can be done to speed up the proceed even more, is to use one VBO for all instance data,
	rather than one VBO per type of instance data - the instance data will be interleaved in one big VBO.
	
	Please improve the Particle system! It needs to be more dynamic. Rewatch episodes if necessary.
		- Reuse particle objects rather than creating new ones.
		- Add an option to choose between normal and non-additive blending.
		- Only sort non-additive blend.
		
Skipped:
	Episode 37
	Procedural terrain
		Not using terrain.
		
Episode 38
Shadow mapping
	Essentially, we will render the scene once per light from the lights first,
	then we render from the cameras perspective. The idea is to create shadow maps that are applied when rendering from the camera.